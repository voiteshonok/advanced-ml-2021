{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from nltk import everygrams\n",
    "from copy import copy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Реализуйте базовый частотный метод по Шерлоку Холмсу:\n",
    "- подсчитайте частоты букв по корпусам (пунктуацию и капитализацию можно просто опустить, а вот пробелы лучше оставить);\n",
    "- возьмите какие-нибудь тестовые тексты (нужно взять по меньшей мере 2-3 предложения, иначе вряд ли сработает), зашифруйте их посредством случайной перестановки символов;\n",
    "- расшифруйте их таким частотным методом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open(\"corpora\\AnnaKarenina.txt\", \"r\", \"utf_8_sig\") as file:\n",
    "    corpus = file.read()\n",
    "    \n",
    "with codecs.open('corpora\\WarAndPeace.txt', 'r', \"utf_8_sig\") as file:\n",
    "    corpus += file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2531073"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "abc = ' абвгдежзийклмнопрстуфхцчшщъыьэюя'\n",
    "\n",
    "def tokenize(text, tokenizer=tokenizer):\n",
    "    text = ''.join([c for c in text if c.lower() in abc])\n",
    "    return ' '.join(tokenizer.tokenize(text.lower()))\n",
    "\n",
    "def get_freqs(text, min_freq=0, n_gram=1):\n",
    "    freqs = dict()\n",
    "    if n_gram > 1:\n",
    "        text = [''.join(ngram) for ngram in everygrams(text, min_len=n_gram, max_len=n_gram)]\n",
    "    for key, value in Counter(text).items():\n",
    "        if value/len(text) > min_freq:\n",
    "            freqs[key] = value/len(text)\n",
    "    return freqs\n",
    "\n",
    "def generate_mapping(freqs):\n",
    "    original = list(freqs.keys())\n",
    "    replacements = np.random.choice(original, replace=False, size=len(freqs))\n",
    "    mapping = dict()\n",
    "    for original_char, replacement_char in zip(original, replacements):\n",
    "        mapping[original_char] = replacement_char\n",
    "    return mapping\n",
    "\n",
    "\n",
    "def apply_mapping(text, mapping):\n",
    "    return ''.join([mapping.get(c, 'ь') for c in text])\n",
    "\n",
    "\n",
    "def get_reverse_mapping(corpus_freqs, text_freqs):\n",
    "    corpus_freqs_sorted = sorted(corpus_freqs.items(), key=lambda x: x[1], reverse=True)\n",
    "    text_freqs_sorted = sorted(text_freqs.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    reverse_mapping = dict()\n",
    "    for text_char, text_freq in text_freqs_sorted:\n",
    "        min_diff = 1\n",
    "        best_char = None\n",
    "        for corpus_char, corpus_freq in corpus_freqs_sorted:\n",
    "            diff = abs(corpus_freq - text_freq)\n",
    "            if diff < min_diff:\n",
    "                best_char = corpus_char\n",
    "                min_diff = diff\n",
    "\n",
    "        reverse_mapping[text_char] = best_char\n",
    "        corpus_freqs_sorted = [(char, freq) for char, freq in corpus_freqs_sorted if char !=best_char]\n",
    "        \n",
    "    return reverse_mapping\n",
    "\n",
    "\n",
    "def char_accuracy(text1, text2):\n",
    "    assert len(text1) == len(text2)\n",
    "    right_chars = 0\n",
    "    for c1, c2 in zip(text1, text2):\n",
    "        right_chars += int(c1 == c2)\n",
    "    return right_chars / len(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_corpus = tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_freqs = get_freqs(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = generate_mapping(corpus_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = tokenized_corpus[100:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'шочмоъяк щвшовьикшаубуфкшюыхпшцмшюыхпмшсмфюмйшцвочмоъяк мйшовьийшцвочмоъяк мшауо увьхшзъушсцкпмшуш вчцщбштвццуоъйбшушядл кшуш вывшушовьившушчвяу вчвосуьшюуоъукцоъ вшяв шъуяоъугыуьмцшркыусупушющбмцкйчмоъишавы мйяв шъуяоъугмццмшсмывцкцмыуьмцшркыусупушющбмцкймццмшсмывцкцмшауымэкямшоу ывьвццксу ш овюцв '"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text = apply_mapping(text, mapping)\n",
    "text_freqs = get_freqs(encoded_text)\n",
    "encoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'отуатвкслчнотндзсобеьехсопржгоиаопржгаомахпаяоинтуатвкслаяотндзяоинтуатвкслаобетленджоэвеомисгаоеолнуичьоцнииетвяьоеокщфлсоеолнрноеотндзноеоункелнунтмедопетвеситвлнокнловектвешредаиоюсремегеопчьаисяуатвзобнрлаякнловектвешаииаомарнисиаредаиоюсремегеопчьаисяаииаомарнисиаобераъскаотелрндниисмелолтнпинл'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_mapping = get_reverse_mapping(corpus_freqs, text_freqs)\n",
    "decoded_text = apply_mapping(encoded_text, reverse_mapping)\n",
    "decoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17333333333333334"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_accuracy(text, decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Биграммы\n",
    "Вряд ли в результате получилась такая уж хорошая расшифровка, разве что если вы брали в качестве тестовых данных целые рассказы. Но и Шерлок Холмс был не так уж прост: после буквы E, которая действительно выделяется частотой, дальше он анализировал уже конкретные слова и пытался угадать, какими они могли бы быть. Я не знаю, как запрограммировать такой интуитивный анализ, так что давайте просто сделаем следующий логический шаг:\n",
    "- подсчитайте частоты биграмм (т.е. пар последовательных букв) по корпусам;\n",
    "- проведите тестирование аналогично п.1, но при помощи биграмм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_freqs_bigram = get_freqs(tokenized_corpus, n_gram=2)\n",
    "text_freqs_bigram = get_freqs(encoded_text, n_gram=2)\n",
    "\n",
    "corpus_freqs_sorted = sorted(corpus_freqs_bigram.items(), key=lambda x: x[1], reverse=True)\n",
    "text_freqs_sorted = sorted(text_freqs_bigram.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reverse_mapping_bigram(corpus_freqs, text_freqs, init_mapping=None):\n",
    "    corpus_freqs_sorted = sorted(corpus_freqs.items(), key=lambda x: x[1], reverse=True)\n",
    "    text_freqs_sorted = sorted(text_freqs.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    if init_mapping is None:\n",
    "        init_mapping = []\n",
    "    reverse_mapping = {k: v for k, v in init_mapping}\n",
    "    \n",
    "    for i, (text_bigram, text_freq) in enumerate(text_freqs_sorted):\n",
    "\n",
    "        filtred_freqs = copy(corpus_freqs_sorted)\n",
    "        \n",
    "        if text_bigram[0] in reverse_mapping.keys():\n",
    "            filtred_freqs = [(bigram, freq) for bigram, freq in filtred_freqs if bigram[0] == reverse_mapping[text_bigram[0]]]\n",
    "            \n",
    "        if text_bigram[1] in reverse_mapping.keys():\n",
    "            filtred_freqs = [(bigram, freq) for bigram, freq in filtred_freqs if bigram[1] == reverse_mapping[text_bigram[1]]]\n",
    "              \n",
    "        min_diff = 1\n",
    "        best_bigram = None\n",
    "        for bigram, freq in filtred_freqs:\n",
    "            diff = abs(freq - text_freq)\n",
    "            if diff < min_diff:\n",
    "                best_bigram = bigram\n",
    "                min_diff = diff\n",
    "                \n",
    "        if text_bigram[0] not in reverse_mapping.keys():\n",
    "            reverse_mapping[text_bigram[0]] = best_bigram[0]\n",
    "            \n",
    "        if text_bigram[1] not in reverse_mapping.keys():\n",
    "            reverse_mapping[text_bigram[1]] = best_bigram[1]\n",
    "\n",
    "        \n",
    "    return reverse_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' о оо к яь  о ст  оо об  ся б ио ся бо ообсон и о оо к яон о стн и о оо к яо ооояо с  л о ои бо о я  иь  л ииоо н  о китя  о я я  о о ст  о   коя   ооос соо о ио я  к я  око отяосои б яоообо сь ои н оо т о яяонк я  око отоиио ооя и иояосои б яоообо сь ои ноиио ооя и ио оояоб ко оояя с ии ооя яо си я'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_mapping_bigram = get_reverse_mapping_bigram(corpus_freqs_bigram, text_freqs_bigram)\n",
    "decoded_text = apply_mapping(encoded_text, reverse_mapping_bigram)\n",
    "decoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22666666666666666"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_accuracy(text, decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. MCMC-сэмплирование\n",
    "Но и это ещё не всё: биграммы скорее всего тоже далеко не всегда работают. Основная часть задания — в том, как можно их улучшить:\n",
    "- предложите метод обучения перестановки символов в этом задании, основанный на MCMC-сэмплировании, но по-прежнему работающий на основе статистики биграмм;\n",
    "- реализуйте и протестируйте его, убедитесь, что результаты улучшились.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freqs_smooth(text, min_freq=0, n_gram=2):\n",
    "    freqs = dict()\n",
    "    vocab_len = len(set(text))**n_gram\n",
    "    if n_gram > 1:\n",
    "        text = [''.join(ngram) for ngram in everygrams(text, min_len=n_gram, max_len=n_gram)]\n",
    "    for key, value in Counter(text).items():\n",
    "        freqs[key] = (value + 1) / (len(text) + vocab_len) # Сглаживаем, чтобы не было нулей\n",
    "    return freqs\n",
    "\n",
    "def get_text_proba(text, mapping, freqs, n_gram=2):\n",
    "    decoded_text = apply_mapping(text, mapping)\n",
    "    log_proba = 0\n",
    "    for i in range(len(decoded_text) - n_gram):\n",
    "        bigram = decoded_text[i: i + n_gram]\n",
    "        bigram_proba = freqs.get(bigram)\n",
    "        if bigram_proba is None:\n",
    "            bigram_proba = 1 / (len(text) + len(abc)**n_gram) # Сглаживаем, чтобы не было нулей\n",
    "            \n",
    "        log_proba += np.log(bigram_proba)\n",
    "    return log_proba\n",
    "        \n",
    "def get_reverse_mapping_mcmc(encoded_text, abc_encoded, abc_corpus, freqs_corpus, n_iters=10000, n_trials=10, n_gram=2):\n",
    "\n",
    "    accept_count = 0\n",
    "    best_mapping = None\n",
    "    all_mappings = []\n",
    "    best_log_likekihood = -np.inf\n",
    "\n",
    "    for trial in tqdm(range(n_trials), leave=False, position=0, total=n_trials):\n",
    "\n",
    "        abc_encoded = list(abc_encoded)\n",
    "        abc_iter = list(abc_corpus)\n",
    "        reverse_mapping = {k: v for k, v in zip(abc_encoded, abc_iter[:len(abc_encoded)])}\n",
    "        log_proba_current = get_text_proba(encoded_text, reverse_mapping, freqs_corpus, n_gram=n_gram)\n",
    "\n",
    "        for i in range(n_iters):\n",
    "            abc_proposal = abc_iter[:]\n",
    "            idx1, idx2 = np.random.choice(len(abc_proposal), replace=False, size=2)\n",
    "            abc_proposal[idx1], abc_proposal[idx2] = abc_proposal[idx2], abc_proposal[idx1]\n",
    "            reverse_mapping_proposal = {k: v for k, v in zip(abc_encoded, abc_proposal[:len(abc_encoded)])}\n",
    "            log_proba_proposal = get_text_proba(encoded_text, reverse_mapping_proposal, freqs_corpus, n_gram=n_gram)\n",
    "\n",
    "            p_accept = np.exp(log_proba_proposal - log_proba_current)\n",
    "\n",
    "            if p_accept > np.random.rand():\n",
    "                accept_count += 1\n",
    "                abc_iter = abc_proposal\n",
    "                log_proba_current = log_proba_proposal\n",
    "                reverse_mapping = reverse_mapping_proposal\n",
    "\n",
    "        if log_proba_current > best_log_likekihood:\n",
    "            best_log_likekihood = log_proba_current\n",
    "            best_mapping = reverse_mapping\n",
    "            \n",
    "        all_mappings.append(reverse_mapping)\n",
    "\n",
    "\n",
    "    print(f'Best likelihood: {best_log_likekihood}')        \n",
    "    print(f'Accept raito: {accept_count / (n_iters * n_trials)}')\n",
    "    return best_mapping, all_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs_corpus = get_freqs_smooth(tokenized_corpus, n_gram=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best likelihood: -1653.5418694166099\n",
      "Accept raito: 0.02628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "best_reverse_mapping, _ = get_reverse_mapping_mcmc(\n",
    "    encoded_text, \n",
    "    abc_encoded=abc, \n",
    "    abc_corpus=abc,\n",
    "    freqs_corpus=freqs_corpus,\n",
    "    n_trials=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23333333333333334"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_accuracy(apply_mapping(encoded_text, best_reverse_mapping), decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' счастривые сельи похожи здум на здума кажзая несчастривая селья несчастрива посвоелу это книма о вечных щенностях о ръфви о веде о селье о черовеческол зостоинстве рев торстогдолан бидокомо зыханиячасть педваярев торстоганна каденинадолан бидокомо зыханияанна каденина подашира совделенников всезнев'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply_mapping(encoded_text, best_reverse_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Расшифруйте сообщение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"დჳჵჂႨშႼႨშჂხჂჲდႨსႹႭჾႣჵისႼჰႨჂჵჂႨႲႹႧჲჂႨსႹႭჾႣჵისႼჰႨჲდႩჳჲႨჇႨႠჲႹქႹႨჳႹႹჱჶდსჂႽႨႩႹჲႹႭႼჰႨჵდქႩႹႨႲႭႹႧჂჲႣჲიႨჳႩႹႭდდႨშჳდქႹႨშႼႨშჳდႨჳხდჵႣჵჂႨႲႭႣშჂჵისႹႨჂႨႲႹჵჇႧჂჲდႨჾႣႩჳჂჾႣჵისႼჰႨჱႣჵჵႨეႣႨႲႹჳჵდხსდდႨႧდჲშდႭჲႹდႨეႣხႣსჂდႨႩჇႭჳႣႨႾႹჲႽႨႩႹსდႧსႹႨႽႨსჂႧდქႹႨსდႨႹჱდჶႣნ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' оеанитслвркдмупяьгыбзчжйшхюэцщфъ', 'ႨდႹჂჵსႣჲჳႭშႩႼႧიႲხჾჰქჇჱႽჶეႠႾნ')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_freqs = get_freqs(message, n_gram=1)\n",
    "\n",
    "corpus_freqs_sorted = sorted(corpus_freqs.items(), key=lambda x: x[1], reverse=True)\n",
    "message_freqs_sorted = sorted(message_freqs.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "abc_corpus = ''.join([c for c, _ in corpus_freqs_sorted])\n",
    "abc_message = ''.join([c for c, _ in message_freqs_sorted])\n",
    "abc_corpus, abc_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs_corpus = get_freqs_smooth(tokenized_corpus, n_gram=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best likelihood: -1231.2446542698947\n",
      "Accept raito: 0.043866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "best_reverse_mapping, _ = get_reverse_mapping_mcmc(\n",
    "    message, \n",
    "    abc_encoded=abc_message, \n",
    "    abc_corpus=abc_corpus,\n",
    "    freqs_corpus=freqs_corpus,\n",
    "    n_iters=10000,\n",
    "    n_trials=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'если вы вимите нордальный или почти нордальный текст у этого соожшения который легко прочитать скорее всего вы все смелали правильно и получите даксидальный жалл за послемнее четвертое замание курса ботя конечно я ничего не ожешащ'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply_mapping(message, best_reverse_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
